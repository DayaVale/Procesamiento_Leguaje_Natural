{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7V_8aPtKZQY"
      },
      "source": [
        "# Topic Modeling\n",
        "\n",
        "- El *topic modeling* es una técnica para extraer los temas \"ocultos\" que hay en un conjunto de textos o corpus.\n",
        "\n",
        "- Es una técnica no supervisada.\n",
        "\n",
        "- Aplicaciones: selección de temas automático de diferentes elementos: tweets, artículos, etc.\n",
        "\n",
        "- La técnicas más usadas para extracción de temas son\n",
        "\n",
        "    - ***LSI:*** Latent Semantic Index\n",
        "\n",
        "    -***LDA***: Latent Dirichlet Allocation\n",
        "\n",
        "    - ***PLSI:*** Probabilistic Latent Semantic Index\n",
        "\n",
        "- Este método consiste en buscar factores que representen a las palbaras y documentos del corpus. A estos factores, se les da el nombre de **factores latentes**\n",
        "\n",
        "- Buscamos: \n",
        "\n",
        "   - Relación entre documentos\n",
        "\n",
        "   - Relación entre palabras\n",
        "\n",
        "   - Extraer los temas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5XNsKiLk2B"
      },
      "source": [
        "Para hacer lo anterior debemos representar el corpus mediante una matriz, que como hemos visto, se hace por medio de una **bolsa de palabras** así:\n",
        "\n",
        "- **Fila:** representa cada documento.\n",
        "\n",
        "- **Columna:** representa cada palabra.\n",
        "\n",
        "- **Entrada $(i,j):$** número de veces que se repite la palabra en el documento.\n",
        "\n",
        "**Obs:** La matriz no necesariamente es cuadrada.\n",
        "\n",
        "Lo que buscamos es hacer una descomposición de la forma:\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  & Corpus &  &  & \\\\ \n",
        " &  &  & _{nxm} &  &  & \\\\ \n",
        " &  &  &  &  &  & \n",
        "\\end{bmatrix} =  \\begin{bmatrix}\n",
        "\\: \\\\ \n",
        "\\: \\\\ \n",
        "  Documentos\\\\ \n",
        "  _{nxK}\\\\ \n",
        "\\:\n",
        "\\end{bmatrix} \\cdot \\begin{bmatrix} \n",
        "  Palabras\\\\ \n",
        "  _{Kxm}\\\\ \n",
        "\\end{bmatrix}$$\n",
        "\n",
        "con\n",
        "\n",
        "$$\\left\\{ \\begin{matrix}\n",
        "n: Número \\: de \\: Documentos\\\\ \n",
        "m: Número \\: de \\: Palabras\\\\ \n",
        "K: Número \\: de \\: Factores \\: Latentes\n",
        "\\end{matrix}\\right.$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0shdLpG-Pwi7"
      },
      "source": [
        "# Vamos a ver un ejemplo numérico\n",
        "\n",
        "* Consideremos matriz que representa una Bolsa de Palabras con:\n",
        "\n",
        "    - Las filas representan a los documentos ($n$ documentos)\n",
        "\n",
        "    - Las columnas representan a las palabras ($m$ palabras)\n",
        "    \n",
        "    \n",
        "* Podemos descomponer esa matriz en tres matrices ***U***, ***S*** y ***V***, cuyo producto matricial es la matriz original ***A***.\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  & A &  &  & \\\\ \n",
        " &  &  & _{nxm} &  &  & \\\\ \n",
        " &  &  &  &  &  & \n",
        "\\end{bmatrix} =  \\begin{bmatrix}\n",
        " &  &  &  & \\\\ \n",
        " &  &  &  & \\\\ \n",
        " &  & U &  & \\\\ \n",
        " &  & _{nxn} &  & \\\\ \n",
        " &  &  &  & \n",
        "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  & S &  &  & \\\\ \n",
        " &  &  & _{nxm} &  &  & \\\\ \n",
        " &  &  &  &  &  & \n",
        "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  & V^{t} &  &  & \\\\ \n",
        " &  &  & _{mxm} &  &  & \\\\ \n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  &  &  &  & \\\\ \n",
        " &  &  &  &  &  & \n",
        "\\end{bmatrix} $$\n",
        "\n",
        "\n",
        "* Cada una de estas matrices contiene la siguiente información:\n",
        "\n",
        "    * ***Matriz U***: Contiene los valores de los ***factores latentes de las palabras***.\n",
        "    * ***Matriz V***: Contiene los valores de los ***factores latentes de los documentos***.\n",
        "    * ***Matriz S***: Matriz en cuya diagonal estan los llamados ***Valores singulares*** que tienen que ser valores decrecientes y no negativos. Los valores de la diagonal representan la importancia que tienen cada uno de los factores latentes de las palabras y de los documentos.\n",
        "\n",
        "<hr>\n",
        "\n",
        "# Cálculo Analítico: de las matrices U, S y V\n",
        "\n",
        "### Para calcular la matriz U.\n",
        "\n",
        "1. Se multiplica la matriz ***A*** por su traspuesta (***$A. A^{T}$***) para obtener una matriz cuadrada de dimensión ***nxn***\n",
        "\n",
        "\n",
        "2. Se calculan los autovalores de la matriz cuadrada (***$A_1 = A. A^{T}$***) usando el polínomio característico:\n",
        "\n",
        "$$det(A_{1}-\\lambda I) = 0$$\n",
        "\n",
        "\n",
        "3. Se calculan los autovectores asociados a cada autovalor (en orden decreciente por autovalor)\n",
        "\n",
        "\n",
        "### Para calcular la matriz $S$\n",
        "\n",
        "\n",
        "1. Una vez hayamos calculado los autovalores de $A_1$, se pone en la diagonal de la matriz ***$S$*** la raiz cuadrada del los autovalores en orden decreciente. El resto de elementos de la matriz ***$S$*** tendrán valor ***$0$***\n",
        "\n",
        "\n",
        "### Cálculo de la matriz V\n",
        "\n",
        "1. Se multiplica ***$A_2 = A^{T}A$*** para obtener una matriz cuadrada de dimensión ***mxm***\n",
        "\n",
        "\n",
        "2. Se calculan los autovectores asociados a cada autovalor (ya calculados) en orden descendente.\n",
        "\n",
        "$$det(A_{2}-\\lambda I) = 0$$\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVRqBuYuRUGr"
      },
      "source": [
        "# Ejemplo \n",
        "Hallar $U$ , $V$ y $S$\n",
        "\n",
        "$$A = \\begin{bmatrix}\n",
        "2 & 3 & 0 \\\\\n",
        "1 & 0 & 1\n",
        "\\end{bmatrix}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE0al5K6Rize"
      },
      "source": [
        "# Ejemplo de ilustración básico\n",
        "\n",
        "Consideremos los siguientes documentos\n",
        "\n",
        "- **doc1:** petro petro reforma ovnis\n",
        "\n",
        "- **doc1:** petro reforma reforma reforma\n",
        "\n",
        "- **doc1:** marzo marzo universo ovnis\n",
        "\n",
        "- **doc1:** universo universo marzo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "xEDLzKb5RsDy",
        "outputId": "ad15bcc1-3402-474a-cc66-7031539a2e47"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marzo</th>\n",
              "      <th>ovnis</th>\n",
              "      <th>petro</th>\n",
              "      <th>reforma</th>\n",
              "      <th>universo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc 1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       marzo  ovnis  petro  reforma  universo\n",
              "doc 1      0      1      2        1         0\n",
              "doc 2      0      0      1        3         0\n",
              "doc 3      2      1      0        0         1\n",
              "doc 4      1      0      0        0         2"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "documentos = ['petro petro reforma ovnis',\n",
        "             'petro reforma reforma reforma',\n",
        "             'marzo marzo universo ovnis',\n",
        "             'universo universo marzo']\n",
        "\n",
        "# vamos a vectorizar\n",
        "vectorizer = CountVectorizer()\n",
        "matrix = vectorizer.fit_transform(documentos)\n",
        "\n",
        "# Creamos el data.frame\n",
        "pd.DataFrame(matrix.toarray(), index=['doc 1', 'doc 2', 'doc 3', 'doc 4'], columns=vectorizer.get_feature_names_out()).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEYo_UwGRnfZ"
      },
      "source": [
        "- Para obtener los *factores latentes* vamos a realizar la ***SVD*** (descomposición en valores singulares).\n",
        "\n",
        "- Cuando aplicamos este método tenemos tres matrices: $U$, $V$, $S$.\n",
        "\n",
        "- Aplicamos los siguiente:\n",
        "\n",
        "   - ***Factores latentes de los documentos*** = $U · S$\n",
        "\n",
        "   - ***Factores latentes de las palabras*** = $S · V$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "NyqUAzMyRv_Q",
        "outputId": "23736d7f-bc6f-4161-f9c3-47878c4933f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Factor 1</th>\n",
              "      <th>Factor 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc 1</th>\n",
              "      <td>2.07</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 2</th>\n",
              "      <td>3.00</td>\n",
              "      <td>-0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 3</th>\n",
              "      <td>0.37</td>\n",
              "      <td>2.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 4</th>\n",
              "      <td>0.18</td>\n",
              "      <td>2.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Factor 1  Factor 2\n",
              "doc 1      2.07      0.04\n",
              "doc 2      3.00     -0.43\n",
              "doc 3      0.37      2.29\n",
              "doc 4      0.18      2.02"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "# para colocar solo dos decimales\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "U_S = svd.fit_transform(matrix)\n",
        "\n",
        "# Resultados\n",
        "pd.DataFrame(U_S, index=['doc 1', 'doc 2', 'doc 3', 'doc 4'], columns=['Factor 1', 'Factor 2']).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeGgBow5R7My"
      },
      "source": [
        "¿Qué podemos decir?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "bhx9eMVlSBfJ",
        "outputId": "ac144ccd-16d2-4254-d705-90c086a07946"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marzo</th>\n",
              "      <th>ovnis</th>\n",
              "      <th>petro</th>\n",
              "      <th>reforma</th>\n",
              "      <th>universo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Factor 1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.95</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Factor 2</th>\n",
              "      <td>2.14</td>\n",
              "      <td>0.76</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          marzo  ovnis  petro  reforma  universo\n",
              "Factor 1   0.25   0.67   1.95     3.02      0.20\n",
              "Factor 2   2.14   0.76  -0.11    -0.41      2.05"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "V_S = np.dot(np.diag(svd.singular_values_), svd.components_)\n",
        "\n",
        "# Resultados\n",
        "pd.DataFrame(V_S, index=['Factor 1', 'Factor 2'], columns=vectorizer.get_feature_names_out()).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWC_kDD7SCxC"
      },
      "source": [
        "¿Qué podemos decir?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xipA6oi3SJEu"
      },
      "source": [
        "# Método LSI :  Latent Semantic Index\n",
        "\n",
        "El ***LSI*** es una técnica de factorización matricial que se aplica en Procesamiento de Lenguaje Natural que busca analizar  las relaciones entre los documentos de un corpus y las palabras. \n",
        "\n",
        "\n",
        "* El ***LSI*** asume que las palabras que tienen un significado similar, aparecerán en partes de documentos similares.\n",
        "\n",
        "\n",
        "* El ***LSI*** tiene como finalidad extraer una serie de factores latentes que caractericen a los documentos y las palabras del corpus.\n",
        "\n",
        "\n",
        "* Necesitaremos una matriz de frecuencias que represente el número de veces que aparecen las palabras en los documentos:\n",
        "\n",
        "    - ***Filas***: Cada fila representa a una palabra.\n",
        "\n",
        "    - ***Columnas***: Cada columna representa a un documento.\n",
        "  \n",
        "    - ***Entrada $(i,j)$***: Cada entrada $(i,j)$ representa el número de veces que aparece la palabra en el documento.\n",
        "    \n",
        "    \n",
        "* El LSI descompone una matriz **$A$** (de frecuencias); que esta formada por el número de apariciones de cada palabra en cada documento, en tres matrices **$U$** , **$V$**, **$S$** cuyo producto matricial es igual a la matriz original **$A$**: \n",
        "\n",
        "\n",
        "$$ SVD(A) = U \\cdot S \\cdot V^{t}$$\n",
        "\n",
        "\n",
        "* Donde cada una de estas matrices contiene la siguiente información:\n",
        "\n",
        "    - ***Matriz $U$*** contiene los valores de los ***factores latentes de las palabras***. \n",
        "\n",
        "    - ***Matriz $V$*** contiene los valores de los ***factores latentes de los documentos***.\n",
        "\n",
        "    - ***Matriz $S$*** es una matriz en cuya diagonal están los llamados valores singulares que son decrecientes y no negativos. Esta matriz representa la ***importancia que tiene cada uno de los factores latentes de las palabras y de los documentos***. \n",
        "    \n",
        "    \n",
        "<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/lsi.png?raw=true\" alt=\"centered image\" width=\"500\" height=\"150\"></center>\n",
        "\n",
        "\n",
        "* Como la matriz ***$S$*** nos informa de la importancia que tiene cada uno de los factores latentes, podemos coger solo los ***K-factores más importantes*** para caracterizar cada una de las palabras y de los items. \n",
        "\n",
        "\n",
        "* De esta forma se trabaja con matrices más reducidas lo que nos permite comprimir la información de la matriz de apariciones.\n",
        "\n",
        "\n",
        "* El SVD tiene una propiedad muy importante que viene dada por el ***teorema de Eckart-Young***, que afirma que la mejor aproximación a la matriz ***$A$*** la obtenemos poniendo a ceros los ***$k$*** valores singulares de menor a mayor valor; es decir, reduciendo la matriz ***$S$***. Por tanto si multiplicamos las submatrices ***$U$*** , ***$S$*** y ***$V$*** obtenemos matriz ***$A'$*** de rango ***$k$*** que mejor aproxima (de acuerdo con la norma de Frobenius) a la matriz ***$A$***.\n",
        "\n",
        "$$\\|A \\|_{F}= \\left( \\sum \\limits_{i=1}^{m} \\sum \\limits_{j=1}^{n} |a_{ij}|^2 \\right)^{1/2} $$\n",
        "\n",
        "<img src=\"./imgs/016_LSI_Matrix_reduc.png\" style=\"width: 800px;\"/>\n",
        "\n",
        "* El valor de ***$k$***, va a representar el número de temas en que vamos a dividir (o Clusterizar) nuestro corpus, por lo tanto la selección del número de temas es un valor que tenemos que definir previamente \n",
        "\n",
        "* Para poder trabajar en la extracción de tópicos y ver las relaciones entre los documentos y las palabras, vamos trabajar con las matrices:\n",
        "\n",
        "    - ***$U_k$***: Estudiar las relaciones entre palabras\n",
        "    - ***$V_k$***: Estudiar las relaciones entre documentos\n",
        "    - ***$k$***: Número de temas que tendrá a priori el Corpus\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PfNfAsYBmtH"
      },
      "source": [
        "# Ejemplo\n",
        "\n",
        "Tenemos el siguiente documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BeF3PjYwFG2c"
      },
      "outputs": [],
      "source": [
        "documento = [\"juego juego juego soccer soccer campeonato campeonato campeonato ronaldo ronaldo ronaldo ronaldo ronaldo messi\",\n",
        "      \"soccer soccer soccer soccer soccer ronaldo ronaldo ronaldo ronaldo messi messi\",\n",
        "      \"juego juego soccer soccer soccer soccer soccer soccer soccer messi messi messi messi messi\",\n",
        "      \"educacion educacion educacion educacion MEN MEN MEN MEN MEN MEN gaviria gaviria gaviria gaviria gaviria\",\n",
        "      \"educacion educacion educacion educacion MEN MEN MEN deuda deuda deuda deuda colegios colegios colegios gaviria\",\n",
        "      \"educacion educacion educacion educacion deuda deuda deuda deuda deuda deuda colegios colegios colegios colegios colegios\",\n",
        "      \"dinero fmi fmi fmi fmi fmi ue ue ue ue pib pib pib ibex ibex\",\n",
        "      \"colegios gaviria dinero dinero dinero dinero fmi fmi fmi fmi ue ue ue ue pib\",\n",
        "      \"MEN deuda colegios gaviria dinero dinero dinero dinero fmi fmi fmi fmi ue ue ue \",\n",
        "      \"soccer educacion pib\",\n",
        "      \"soccer colegios campeonato gaviria\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X62RZKLtph6K"
      },
      "source": [
        "este trata tres temas a saber: soccer, educación, economía"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0xi5O12FcqA",
        "outputId": "42191497-c86b-4b83-83df-5a6a0281c2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diccionario:\n",
            "{'MEN': 5,\n",
            " 'campeonato': 0,\n",
            " 'colegios': 8,\n",
            " 'deuda': 9,\n",
            " 'dinero': 10,\n",
            " 'educacion': 6,\n",
            " 'fmi': 11,\n",
            " 'gaviria': 7,\n",
            " 'ibex': 12,\n",
            " 'juego': 1,\n",
            " 'messi': 2,\n",
            " 'pib': 13,\n",
            " 'ronaldo': 3,\n",
            " 'soccer': 4,\n",
            " 'ue': 14}\n",
            "\n",
            "Bolsa de Palabras:\n",
            "[[(0, 3), (1, 3), (2, 1), (3, 5), (4, 2)],\n",
            " [(2, 2), (3, 4), (4, 5)],\n",
            " [(1, 2), (2, 5), (4, 7)],\n",
            " [(5, 6), (6, 4), (7, 5)],\n",
            " [(5, 3), (6, 4), (7, 1), (8, 3), (9, 4)],\n",
            " [(6, 4), (8, 5), (9, 6)],\n",
            " [(10, 1), (11, 5), (12, 2), (13, 3), (14, 4)],\n",
            " [(7, 1), (8, 1), (10, 4), (11, 4), (13, 1), (14, 4)],\n",
            " [(5, 1), (7, 1), (8, 1), (9, 1), (10, 4), (11, 4), (14, 3)],\n",
            " [(4, 1), (6, 1), (13, 1)],\n",
            " [(0, 1), (4, 1), (7, 1), (8, 1)]]\n"
          ]
        }
      ],
      "source": [
        "# para imprimir de otra forma\n",
        "from pprint import pprint\n",
        "# diccionario de gensim\n",
        "from gensim import corpora\n",
        "from collections import defaultdict\n",
        "\n",
        "# Tokenizamos\n",
        "documents = [word.split() for word in documento]\n",
        "\n",
        "# Creamos el diccionario (vocabulario)\n",
        "frequency = defaultdict(int)\n",
        "for doc in documents:\n",
        "    for token in doc:\n",
        "        frequency[token] += 1\n",
        "        \n",
        "documents = [[token for token in doc] for doc in documents]\n",
        "dictionary = corpora.Dictionary(documents)\n",
        "print('Diccionario:')\n",
        "pprint(dictionary.token2id)\n",
        "\n",
        "# Creamos la Bolsa de Palabras\n",
        "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
        "print('\\nBolsa de Palabras:')\n",
        "pprint(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eJrvZqREb3t"
      },
      "source": [
        "# Creación del modelo\n",
        "\n",
        "- La librería Gensim tiene ***LSI*** en **LSiModel**\n",
        "\n",
        "- Requerimos\n",
        "\n",
        "   - Corpus\n",
        "\n",
        "   - Número de temas\n",
        "\n",
        "   - Diccionario o vocabulario del corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yCAjICK0FpMC"
      },
      "outputs": [],
      "source": [
        "from gensim.models import LsiModel\n",
        "lsi_model = LsiModel(corpus=corpus, num_topics=3, id2word=dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY99yYcuE0_U"
      },
      "source": [
        "- Vamos a ver la matriz ***$U$***\n",
        "\n",
        "- Esta matriz tiene los ***factores latentes de cada una de las palabras***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS0iHg4UFtDa",
        "outputId": "2296d536-0e81-4421-a5c2-1f6f71229a63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.0080157 , -0.12147793, -0.00477548],\n",
              "       [ 0.00764122, -0.23838329, -0.01351154],\n",
              "       [ 0.01436787, -0.44343298, -0.02506618],\n",
              "       [ 0.01216459, -0.38311209, -0.02178312],\n",
              "       [ 0.03238081, -0.76194106, -0.03952318],\n",
              "       [ 0.34610872,  0.00491806,  0.20925565],\n",
              "       [ 0.45080378, -0.00342558,  0.35923484],\n",
              "       [ 0.26841352,  0.00105663,  0.07889487],\n",
              "       [ 0.37700371,  0.00176928,  0.1817653 ],\n",
              "       [ 0.42300698,  0.00545779,  0.28893431],\n",
              "       [ 0.25466521,  0.03058342, -0.36521087],\n",
              "       [ 0.34588865,  0.04406739, -0.55200635],\n",
              "       [ 0.04561172,  0.00674199, -0.09339774],\n",
              "       [ 0.09993979,  0.00781257, -0.18348589],\n",
              "       [ 0.29289059,  0.03742915, -0.47017643]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "U_matrix = lsi_model.projection.u\n",
        "U_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZvyYnCzFEr7"
      },
      "source": [
        "Podemos ver los factores asociados a cada palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "6ijThR6cFwd0",
        "outputId": "8775738c-d877-4294-8105-82f8fc7d1665"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>campeonato</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>juego</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>messi</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ronaldo</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soccer</th>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEN</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>educacion</th>\n",
              "      <td>0.45</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gaviria</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>colegios</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deuda</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dinero</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fmi</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ibex</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pib</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ue</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Topic 1  Topic 2  Topic 3\n",
              "campeonato     0.01    -0.12    -0.00\n",
              "juego          0.01    -0.24    -0.01\n",
              "messi          0.01    -0.44    -0.03\n",
              "ronaldo        0.01    -0.38    -0.02\n",
              "soccer         0.03    -0.76    -0.04\n",
              "MEN            0.35     0.00     0.21\n",
              "educacion      0.45    -0.00     0.36\n",
              "gaviria        0.27     0.00     0.08\n",
              "colegios       0.38     0.00     0.18\n",
              "deuda          0.42     0.01     0.29\n",
              "dinero         0.25     0.03    -0.37\n",
              "fmi            0.35     0.04    -0.55\n",
              "ibex           0.05     0.01    -0.09\n",
              "pib            0.10     0.01    -0.18\n",
              "ue             0.29     0.04    -0.47"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(U_matrix, columns=['Topic 1', 'Topic 2', 'Topic 3'], \n",
        "             index=dictionary.token2id.keys()).head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn57hRiJFo-Y"
      },
      "source": [
        "Ahora, veamos la matriz ***$S$***, la cual nos da la importancia de los **factores latentes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdmpec0cF2BG",
        "outputId": "4533a1fd-23bf-46d0-bc32-790e2ca3bea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([12.47067133, 11.39302903, 11.08980301])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "S_matrix = lsi_model.projection.s\n",
        "S_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFNWPFQRF2JI"
      },
      "source": [
        "Luego, la matriz ***$V$*** que tiene los **fcatores latentes de cada documento del corpus**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJrTkeUuF5ZK",
        "outputId": "d93b2a90-af69-4196-eb32-b0a81c721dc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.01498903, -0.43556977, -0.02415635],\n",
              "       [ 0.01918888, -0.54673956, -0.03019718],\n",
              "       [ 0.02516204, -0.70459921, -0.03868565],\n",
              "       [ 0.41873726,  0.00185106,  0.27835911],\n",
              "       [ 0.47575577,  0.00256714,  0.34668193],\n",
              "       [ 0.49927348,  0.00244806,  0.36784891],\n",
              "       [ 0.28440438,  0.03840583, -0.51788127],\n",
              "       [ 0.3463434 ,  0.04028414, -0.49346234],\n",
              "       [ 0.37651704,  0.03722386, -0.38959647],\n",
              "       [ 0.04675966, -0.06649277,  0.01228388],\n",
              "       [ 0.05499413, -0.07729227,  0.01950995]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.matutils import corpus2dense\n",
        "V_matrix = corpus2dense(lsi_model[corpus], len(lsi_model.projection.s)).T / lsi_model.projection.s \n",
        "V_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh42a8kZHaFV"
      },
      "source": [
        "De igual forma que con **$U$** hallamos los factores por documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "woieVvRtF8Jg",
        "outputId": "3e44d595-5331-4bab-c6e1-a17bedbfa3cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc 1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 2</th>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 3</th>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 4</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 5</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 6</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 7</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 8</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 9</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 10</th>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc 11</th>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Topic 1  Topic 2  Topic 3\n",
              "doc 1      0.01    -0.44    -0.02\n",
              "doc 2      0.02    -0.55    -0.03\n",
              "doc 3      0.03    -0.70    -0.04\n",
              "doc 4      0.42     0.00     0.28\n",
              "doc 5      0.48     0.00     0.35\n",
              "doc 6      0.50     0.00     0.37\n",
              "doc 7      0.28     0.04    -0.52\n",
              "doc 8      0.35     0.04    -0.49\n",
              "doc 9      0.38     0.04    -0.39\n",
              "doc 10     0.05    -0.07     0.01\n",
              "doc 11     0.05    -0.08     0.02"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = ['doc {}'.format(i+1) for i,doc in enumerate(documents)]\n",
        "pd.DataFrame(V_matrix, index=index, columns=['Topic 1', 'Topic 2', 'Topic 3'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQnawDMoHq_X"
      },
      "source": [
        "¿Que podemos indicar?\n",
        "\n",
        "- El valor de los factores guarda alguna relación con el tema que se trata en el documento. \n",
        "\n",
        "   - (doc4, doc5, doc6) guardan relación con el tópico 1 y están relacionados.\n",
        "\n",
        "   - (doc1, doc2, doc3) guardan relación con el tópico 2.\n",
        "\n",
        "- Palabras características de cada tema tienen valores latentes similares\n",
        "\n",
        "- Si graficamos factores latentes de palabras y documentos (factores 2 y 3) están muy cerca entre cada uno de ellos. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgluAzqyFlpA"
      },
      "source": [
        "Veamos la gráfica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "_e4Gli6MH4ZS",
        "outputId": "6963b4a5-d46c-4978-ecf8-4fe242f53aed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>Doc 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>Doc 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>Doc 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>Doc 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>Doc 5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>Doc 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>Doc 7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>Doc 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>Doc 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Doc 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.02</td>\n",
              "      <td>Doc 11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      f2    f3   group\n",
              "0  -0.44 -0.02   Doc 1\n",
              "1  -0.55 -0.03   Doc 2\n",
              "2  -0.70 -0.04   Doc 3\n",
              "3   0.00  0.28   Doc 4\n",
              "4   0.00  0.35   Doc 5\n",
              "5   0.00  0.37   Doc 6\n",
              "6   0.04 -0.52   Doc 7\n",
              "7   0.04 -0.49   Doc 8\n",
              "8   0.04 -0.39   Doc 9\n",
              "9  -0.07  0.01  Doc 10\n",
              "10 -0.08  0.02  Doc 11"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.DataFrame({'f2': V_matrix[:,1], 'f3': V_matrix[:,2],\n",
        "                   'group': ['Doc {}'.format(i+1) for i,doc in enumerate(documents)]})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dqb6KscTurU3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'f2': V_matrix[:,1], 'f3': V_matrix[:,2],\n",
        "                   'group': ['Doc {}'.format(i+1) for i,doc in enumerate(documents)]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "KKXFCCj1usbG",
        "outputId": "f5f6c8fc-ed5e-44d8-d6f6-d1d0c37704c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>Doc 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>Doc 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>Doc 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>Doc 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>Doc 5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>Doc 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>Doc 7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>Doc 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>Doc 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Doc 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.02</td>\n",
              "      <td>Doc 11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      f2    f3   group\n",
              "0  -0.44 -0.02   Doc 1\n",
              "1  -0.55 -0.03   Doc 2\n",
              "2  -0.70 -0.04   Doc 3\n",
              "3   0.00  0.28   Doc 4\n",
              "4   0.00  0.35   Doc 5\n",
              "5   0.00  0.37   Doc 6\n",
              "6   0.04 -0.52   Doc 7\n",
              "7   0.04 -0.49   Doc 8\n",
              "8   0.04 -0.39   Doc 9\n",
              "9  -0.07  0.01  Doc 10\n",
              "10 -0.08  0.02  Doc 11"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "WiuTIIptGBvq",
        "outputId": "d346454c-351c-40b1-fe31-71f8910caf13"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.DataFrame({'f2': V_matrix[:,1], 'f3': V_matrix[:,2],\n",
        "                   'group': ['Doc {}'.format(i+1) for i,doc in enumerate(documents)]})\n",
        "\n",
        "sns.lmplot(data = df, x= \"f2\" , y = \"f3\", fit_reg=False, height=6, aspect=2)\n",
        "\n",
        "plt.title('Representación de los documentos (Factores 2 y 3)')\n",
        "plt.xlabel('Factor 2')\n",
        "plt.ylabel('Factor 3')\n",
        "\n",
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "        ax.text(point['x']+.02, point['y'], str(point['val']))\n",
        "        \n",
        "label_point(df.f2, df.f3, df.group, plt.gca())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "TE686fRoJur2",
        "outputId": "c0f97099-c572-4121-e24e-bfbc69b5c192"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame({'f2': U_matrix[:,1], 'f3': U_matrix[:,2],\n",
        "                   'group': [word for word in dictionary.token2id.keys()]})\n",
        "\n",
        "sns.lmplot(data = df, x= \"f2\" , y = \"f3\", fit_reg=False, height=6, aspect=2)\n",
        "\n",
        "plt.title('Representación de los documentos (Factores 2 y 3)')\n",
        "plt.xlabel('Factor 2')\n",
        "plt.ylabel('Factor 3')\n",
        "\n",
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "        ax.text(point['x']+.02, point['y'], str(point['val']))\n",
        "        \n",
        "label_point(df.f2, df.f3, df.group, plt.gca())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xG67Bl7JbXY"
      },
      "source": [
        "Gensim nos muestra una fórmula por tema.\n",
        "\n",
        "- Esta indica el grado de pertenencia a un determinado tema \n",
        "\n",
        "- El valor más grande hay más posibildidad de aparcer en ese tema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9jc7JDvJgv_",
        "outputId": "e809b7b9-f8e2-42c9-8140-41d75219fcf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.451*\"educacion\" + 0.423*\"deuda\" + 0.377*\"colegios\" + 0.346*\"MEN\" + 0.346*\"fmi\" + 0.293*\"ue\" + 0.268*\"gaviria\" + 0.255*\"dinero\" + 0.100*\"pib\" + 0.046*\"ibex\"'),\n",
              " (1,\n",
              "  '-0.762*\"soccer\" + -0.443*\"messi\" + -0.383*\"ronaldo\" + -0.238*\"juego\" + -0.121*\"campeonato\" + 0.044*\"fmi\" + 0.037*\"ue\" + 0.031*\"dinero\" + 0.008*\"pib\" + 0.007*\"ibex\"'),\n",
              " (2,\n",
              "  '-0.552*\"fmi\" + -0.470*\"ue\" + -0.365*\"dinero\" + 0.359*\"educacion\" + 0.289*\"deuda\" + 0.209*\"MEN\" + -0.183*\"pib\" + 0.182*\"colegios\" + -0.093*\"ibex\" + 0.079*\"gaviria\"')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lsi_model.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdh0kk-CJ-Ge"
      },
      "source": [
        "# Ejemplo\n",
        "\n",
        "- Podemos asignar un tema a un documento nuevo\n",
        "\n",
        "- Se debe calcular los fcatores latentes del nuevo documento en función del vector de apariciones de palabras y calcular la similaridad con el resto de documentos en función de sus factores latentes.\n",
        "\n",
        "- Usamos la fórmula\n",
        "\n",
        "$$FactoresLatentes(new) = VectorPalabras(new). U_k S^{-1}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B6nM0SnnL2Co"
      },
      "outputs": [],
      "source": [
        "new_doc = \"soccer soccer messi colegios educacion educacion educacion MEN\"\n",
        "new_vec = dictionary.doc2bow(new_doc.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "PD6nknSAMHeV",
        "outputId": "31038d1d-7a54-4fcd-df65-1da6fa4be4c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Valor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic 1</th>\n",
              "      <td>0</td>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 3</th>\n",
              "      <td>2</td>\n",
              "      <td>1.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Valor\n",
              "Topic 1  0   2.15\n",
              "Topic 2  1  -1.97\n",
              "Topic 3  2   1.36"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtenemos los factores latentes del nuevo documento\n",
        "vec_lsi = lsi_model[new_vec]\n",
        "\n",
        "pd.DataFrame(vec_lsi, index=['Topic 1', 'Topic 2', 'Topic 3'], columns=['', 'Valor']).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UPh3ElAMNLb"
      },
      "source": [
        "Luego calculamos las similaridades entre documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "IMje5GpSMQ-1",
        "outputId": "19dae844-e556-47bd-f092-af482c60a2e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Documento (indice)</th>\n",
              "      <th>Similaridad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Documento (indice)  Similaridad\n",
              "0                   10         0.96\n",
              "1                    9         0.94\n",
              "2                    5         0.79\n",
              "3                    3         0.79\n",
              "4                    4         0.79\n",
              "5                    2         0.61\n",
              "6                    1         0.61\n",
              "7                    0         0.61\n",
              "8                    8         0.16\n",
              "9                    7         0.04\n",
              "10                   6        -0.05"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim import similarities\n",
        "\n",
        "# Calcular las similaridades\n",
        "index = similarities.MatrixSimilarity(lsi_model[corpus])\n",
        "sims = index[vec_lsi]\n",
        "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "\n",
        "pd.DataFrame(sims, columns=['Documento (indice)', 'Similaridad']).head(11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAm1w-xFMZME"
      },
      "source": [
        "Vemos que tiene mayor similaridad con los documentos 0, 1 y 2 que hablan de soccer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTessBr1qbtK"
      },
      "source": [
        "# LDA: Latent Dirichlet Allocation\n",
        "\n",
        "\n",
        "* El LDA, es un ***modelo probabilístico*** que se enmarca dentro de los ***modelos generativos*** ya que trata de describir como se crea un documento. (http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)\n",
        "\n",
        "\n",
        "* El LDA propone que ***un documento se crea mediante la selección de los temas y las palabras de acuerdo a las representaciones probabilísticas del texto natural del documento***.\n",
        "\n",
        "\n",
        "* El LDA calcula **dos matrices de probabilidad P(w|z) y P(z|θ)**, donde:\n",
        "\n",
        "    - **P(w|z)**: es la probabilidad de que dado un tema salga una palabra\n",
        "    - **P(z|θ)**: es la probabilidad de que un documento pertenezca a un tema.\n",
        "    \n",
        "$$ P(w|\\theta) = \\sum_{z \\in  Z} P(w | z) \\cdot P(z|\\theta) $$\n",
        "\n",
        "\n",
        "* La representación en \"*Plate Notation*\" o notación de placas del LDA es la siguiente:\n",
        "\n",
        "<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/LDA.png?raw=true\" alt=\"centered image\" width=\"500\" height=\"300\"></center>\n",
        "\n",
        "* Donde\n",
        "\n",
        "    + ***$K$***: Número de temas. \n",
        "    + ***$N$***: Número de palabras\n",
        "    + ***$M$***: Número de documentos: \n",
        "    + ***$\\alpha$***: Parámetro de Dirichlet. Este parámetro es un vector de $K$ componentes que describe el conocimiento a priori que se tiene sobre como los temas se distribuyen en los documentos. \n",
        "        * Pocos temas -> Valor de $\\alpha$ pequeño\n",
        "        * Muchos temas  -> Valor de $\\alpha$ grande\n",
        "    + ***$\\beta$***: Parámetro de Dirichlet. Este parámetro es un vector de $N$ componentes que describe el conocimiento a priori que se tiene sobre como las palabras se distribuyen en cada tema. \n",
        "        * Tema con pocas palabras -> Valor de $\\beta$ cercano a cero\n",
        "        * Tema con muchas palabras -> Valor de $\\beta$ cercano a uno\n",
        "    + ***$\\theta$***: Distribución de probabilidad de que un documento pertenezca a un tema. \n",
        "    + ***$Z$***: Distribución de probabilidad de que una palabra pertenezca a un tema. \n",
        "    + ***$W$***: Identifica todas las palabras en todos los documentos.\n",
        "    + ***$\\varphi$***: Distribución de probabilidad de que dado un tema salga una palabra.\n",
        "    \n",
        "* Haciendo la comparación con el LSI, el ***LDA nos tienen que proporcionar***:\n",
        "    - Matriz de probabilidades \"***Temas-Palabras***\": Nos indica la probabilidad de que dado un tema, salga una palabra. \n",
        "    - Matriz de probabilidades \"***Documentos-Temas***\": Nos indica la probabilidad de que un documento pertenezca a un tema.\n",
        "    \n",
        "    \n",
        "* De esta manera podemos ver las relaciones entre palabras y entre documentos.\n",
        "\n",
        "\n",
        "* ***OBSERVACIÓN IMPORTANTE***: *El LDA trabaja con distribuciones de probabilidad que representan la probabilidad de pertenencia de cada palabra o documento a cada tema. Estas distribuciones de probabilidad no tienen que ser tratadas como vectores de factores latentes (como en el LSI) para calcular similaridades entre documentos, ya que al tratarse de distribuciones de probabilidad no hay que aplicar medidas de distancias para calcular similaridades; si no la ***Divergencia de Kullback-Liebler (KL)*** para estudiar las similaridades entre distribuciones de probabilidad.*\n",
        "\n",
        "\n",
        "$$ KL(p ||q) = \\sum_{i}p(i)ln \\frac{p(i)}{q(i)} $$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gbCvr0_itAr1"
      },
      "source": [
        "Vamos a revisar el ejemplo que hicimos con LSI, ahora con LDA es con probabilidades y la distancia de logaritmo, encambio LSI es con Frecuencias y distancia euclidiana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CKeTbkQ8tNXi"
      },
      "outputs": [],
      "source": [
        "documento = [\"juego juego juego soccer soccer campeonato campeonato campeonato ronaldo ronaldo ronaldo ronaldo ronaldo messi\",\n",
        "      \"soccer soccer soccer soccer soccer ronaldo ronaldo ronaldo ronaldo messi messi\",\n",
        "      \"juego juego soccer soccer soccer soccer soccer soccer soccer messi messi messi messi messi\",\n",
        "      \"educacion educacion educacion educacion MEN MEN MEN MEN MEN MEN gaviria gaviria gaviria gaviria gaviria\",\n",
        "      \"educacion educacion educacion educacion MEN MEN MEN deuda deuda deuda deuda colegios colegios colegios gaviria\",\n",
        "      \"educacion educacion educacion educacion deuda deuda deuda deuda deuda deuda colegios colegios colegios colegios colegios\",\n",
        "      \"dinero fmi fmi fmi fmi fmi ue ue ue ue pib pib pib ibex ibex\",\n",
        "      \"colegios gaviria dinero dinero dinero dinero fmi fmi fmi fmi ue ue ue ue pib\",\n",
        "      \"MEN deuda colegios gaviria dinero dinero dinero dinero fmi fmi fmi fmi ue ue ue \",\n",
        "      \"soccer educacion pib\",\n",
        "      \"soccer colegios campeonato gaviria\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-bst97ZtUWc"
      },
      "source": [
        "Bolsa de palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFnzQW9XtTzU",
        "outputId": "f526e86f-dbc1-476a-d50f-4ced671115f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diccionario:\n",
            "{'MEN': 5,\n",
            " 'campeonato': 0,\n",
            " 'colegios': 8,\n",
            " 'deuda': 9,\n",
            " 'dinero': 10,\n",
            " 'educacion': 6,\n",
            " 'fmi': 11,\n",
            " 'gaviria': 7,\n",
            " 'ibex': 12,\n",
            " 'juego': 1,\n",
            " 'messi': 2,\n",
            " 'pib': 13,\n",
            " 'ronaldo': 3,\n",
            " 'soccer': 4,\n",
            " 'ue': 14}\n",
            "\n",
            "Bolsa de Palabras:\n",
            "[[(0, 3), (1, 3), (2, 1), (3, 5), (4, 2)],\n",
            " [(2, 2), (3, 4), (4, 5)],\n",
            " [(1, 2), (2, 5), (4, 7)],\n",
            " [(5, 6), (6, 4), (7, 5)],\n",
            " [(5, 3), (6, 4), (7, 1), (8, 3), (9, 4)],\n",
            " [(6, 4), (8, 5), (9, 6)],\n",
            " [(10, 1), (11, 5), (12, 2), (13, 3), (14, 4)],\n",
            " [(7, 1), (8, 1), (10, 4), (11, 4), (13, 1), (14, 4)],\n",
            " [(5, 1), (7, 1), (8, 1), (9, 1), (10, 4), (11, 4), (14, 3)],\n",
            " [(4, 1), (6, 1), (13, 1)],\n",
            " [(0, 1), (4, 1), (7, 1), (8, 1)]]\n"
          ]
        }
      ],
      "source": [
        "# Tokenizamos\n",
        "document = [word.split() for word in documento]\n",
        "\n",
        "# Creamos el diccionario (vocabulario)\n",
        "frequency = defaultdict(int)\n",
        "for doc in documents:\n",
        "    for token in doc:\n",
        "        frequency[token] += 1\n",
        "        \n",
        "documents = [[token for token in doc] for doc in documents]\n",
        "dictionary = corpora.Dictionary(documents)\n",
        "print('Diccionario:')\n",
        "pprint(dictionary.token2id)\n",
        "\n",
        "# Creamos la Bolsa de Palabras\n",
        "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
        "print('\\nBolsa de Palabras:')\n",
        "pprint(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtRyx4CovlqG"
      },
      "source": [
        "## Generación del Modelo:\n",
        "\n",
        "* Gensim tiene implementado el LDA en la clase ***LdaModel***: https://radimrehurek.com/gensim/models/ldamodel.html\n",
        "\n",
        "\n",
        "* Como parámetros relevantes necesita:\n",
        "    1. Corpus\n",
        "    2. Número de Topics\n",
        "    3. Diccionario o Vocabulario del Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gihWigz-vlZs"
      },
      "outputs": [],
      "source": [
        "from gensim.models import LdaModel\n",
        "\n",
        "lda_model = LdaModel(corpus=corpus, \n",
        "                     num_topics=3, \n",
        "                     id2word=dictionary, \n",
        "                     random_state=168)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6UbTgWMXv26J"
      },
      "source": [
        "## Matriz de probabilidades \"***Documentos-Temas***\" - Matriz U \n",
        "\n",
        "* Obtenemos la probabilidad de que cada documento pertenezca a uno de los 3 temas de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iKO41f5Pv8Hl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.9554735 , 0.02226917, 0.02225735],\n",
              "       [0.9443553 , 0.0278324 , 0.02781233],\n",
              "       [0.955479  , 0.02226874, 0.02225227],\n",
              "       [0.02358868, 0.95468956, 0.02172177],\n",
              "       [0.02161127, 0.9571557 , 0.02123299],\n",
              "       [0.02107015, 0.95780784, 0.02112204],\n",
              "       [0.02093267, 0.02089469, 0.9581726 ],\n",
              "       [0.02132919, 0.02236205, 0.9563087 ],\n",
              "       [0.02175598, 0.10594875, 0.87229526],\n",
              "       [0.47131318, 0.26471367, 0.26397318],\n",
              "       [0.66139346, 0.26845714, 0.07014938]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "docs_topics = np.array([[tup[1] for tup in lst] for lst in lda_model[corpus]])\n",
        "docs_topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj7ZSI-XwGZc"
      },
      "source": [
        "Se puede observar que:\n",
        "\n",
        "- Devuelve para cada documento la probabilidad de que el documento pertenezca a cada tema y que es un vector de probabilidades ya que la suma de las probabilidades es igual a $1$.\n",
        "\n",
        "- Para ver los factores de cada una de las palabras se hace lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "92XoIQFlwS74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc 1</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 2</th>\n",
              "      <td>0.94</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 3</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 4</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 5</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 6</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 7</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 8</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 9</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 10</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc 11</th>\n",
              "      <td>0.66</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Topic 1  Topic 2  Topic 3\n",
              "Doc 1      0.96     0.02     0.02\n",
              "Doc 2      0.94     0.03     0.03\n",
              "Doc 3      0.96     0.02     0.02\n",
              "Doc 4      0.02     0.95     0.02\n",
              "Doc 5      0.02     0.96     0.02\n",
              "Doc 6      0.02     0.96     0.02\n",
              "Doc 7      0.02     0.02     0.96\n",
              "Doc 8      0.02     0.02     0.96\n",
              "Doc 9      0.02     0.11     0.87\n",
              "Doc 10     0.47     0.26     0.26\n",
              "Doc 11     0.66     0.27     0.07"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "index = ['Doc {}'.format(i+1) for i,doc in enumerate(documents)]\n",
        "pd.DataFrame(docs_topics, index=index, columns=['Topic 1', 'Topic 2', 'Topic 3']).head(11)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Tarea: Corran el LDA 2500 documentos de 50 o 100*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3SC2pscwZ6Y"
      },
      "source": [
        "## Matriz de probabilidades \"***Temas-Palabras***\" - Matriz V\n",
        "\n",
        "\n",
        "* Obtenemos la probabilidad de que dado uno de los 3 temas aparezca una de las 15 palabras. Al igual que en la matriz anterior la suma de todas las probabilidades de las palabras en un tema tiene que sumar $1$.\n",
        "\n",
        "\n",
        "* A continuación obtenemos la probabilidad de que dado un tema aparezca una palabra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rrngE5s3whsg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.07191384, 0.08909308, 0.13870065, 0.15540095, 0.26856995,\n",
              "        0.06613762, 0.05746238, 0.08111635, 0.02175318, 0.00639754,\n",
              "        0.00625349, 0.00662618, 0.0057096 , 0.01868422, 0.00618097],\n",
              "       [0.00883434, 0.00860135, 0.00886778, 0.00929843, 0.01410442,\n",
              "        0.13715622, 0.24607542, 0.06816371, 0.20073204, 0.24763939,\n",
              "        0.0089917 , 0.009497  , 0.00826988, 0.01391835, 0.00985007],\n",
              "       [0.00720722, 0.00698804, 0.00781871, 0.00761892, 0.00916188,\n",
              "        0.02773269, 0.0079182 , 0.04699612, 0.04775178, 0.02722945,\n",
              "        0.18444683, 0.2632963 , 0.046198  , 0.08595766, 0.22367825]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_topics = lda_model.get_topics()\n",
        "words_topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaE-F6IWwjw2"
      },
      "source": [
        "Colocamos los resultados en una tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JWRfv3cEwmQr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>campeonato</th>\n",
              "      <th>juego</th>\n",
              "      <th>messi</th>\n",
              "      <th>ronaldo</th>\n",
              "      <th>soccer</th>\n",
              "      <th>MEN</th>\n",
              "      <th>educacion</th>\n",
              "      <th>gaviria</th>\n",
              "      <th>colegios</th>\n",
              "      <th>deuda</th>\n",
              "      <th>dinero</th>\n",
              "      <th>fmi</th>\n",
              "      <th>ibex</th>\n",
              "      <th>pib</th>\n",
              "      <th>ue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic 1</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         campeonato  juego  messi  ronaldo  soccer  MEN  educacion  gaviria  \\\n",
              "Topic 1        0.07   0.09   0.14     0.16    0.27 0.07       0.06     0.08   \n",
              "Topic 2        0.01   0.01   0.01     0.01    0.01 0.14       0.25     0.07   \n",
              "Topic 3        0.01   0.01   0.01     0.01    0.01 0.03       0.01     0.05   \n",
              "\n",
              "         colegios  deuda  dinero  fmi  ibex  pib   ue  \n",
              "Topic 1      0.02   0.01    0.01 0.01  0.01 0.02 0.01  \n",
              "Topic 2      0.20   0.25    0.01 0.01  0.01 0.01 0.01  \n",
              "Topic 3      0.05   0.03    0.18 0.26  0.05 0.09 0.22  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(words_topics, index=['Topic 1', 'Topic 2', 'Topic 3'], columns=dictionary.token2id.keys()).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST3vHqs3wqeS"
      },
      "source": [
        "## Palabras (terminos) más representativas de un tema (topic)\n",
        "\n",
        "Dado que podemos obtener la probabilidad de que dada una palabra (termino) esta pertenezca a un tema (topic), podemos obtener las palabras más representativas por topic de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Euf8d11mwqSl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Topic 1\n",
            "['soccer', 'ronaldo', 'messi', 'juego', 'gaviria']\n",
            "\n",
            "Topic 2\n",
            "['deuda', 'educacion', 'colegios', 'MEN', 'gaviria']\n",
            "\n",
            "Topic 3\n",
            "['fmi', 'ue', 'dinero', 'pib', 'colegios']\n"
          ]
        }
      ],
      "source": [
        "dictionary.id2token\n",
        "for i in range(3):\n",
        "    print('\\nTopic {i}'.format(i=i+1))\n",
        "    pprint([dictionary.id2token[term[0]] for term in lda_model.get_topic_terms(i)[0:5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm1t2y_tw-g2"
      },
      "source": [
        "## Temas y Palabras\n",
        "\n",
        "* Gensim nos devuelve un \"formula\" por tema (Topic) que aplicada a las apariciones de las palabras en los documentos nos indica la pertenencia del nuevo documento a ese tema. El que mayor valor tenga tras aplicar la fórmula del tema al documento significará que tiene mayor propensión a pertenecer a ese tema.\n",
        "\n",
        "* Esa fórmula la construye como el sumatorio de la aparición de la palabra en el documento, multiplicado por la probabilidad de que en ese temá aparezca esa palabra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "J-Ib1YKtxHoy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.269*\"soccer\" + 0.155*\"ronaldo\" + 0.139*\"messi\" + 0.089*\"juego\" + 0.081*\"gaviria\" + 0.072*\"campeonato\" + 0.066*\"MEN\" + 0.057*\"educacion\" + 0.022*\"colegios\" + 0.019*\"pib\" + 0.007*\"fmi\" + 0.006*\"deuda\" + 0.006*\"dinero\" + 0.006*\"ue\" + 0.006*\"ibex\"'),\n",
              " (1,\n",
              "  '0.248*\"deuda\" + 0.246*\"educacion\" + 0.201*\"colegios\" + 0.137*\"MEN\" + 0.068*\"gaviria\" + 0.014*\"soccer\" + 0.014*\"pib\" + 0.010*\"ue\" + 0.009*\"fmi\" + 0.009*\"ronaldo\" + 0.009*\"dinero\" + 0.009*\"messi\" + 0.009*\"campeonato\" + 0.009*\"juego\" + 0.008*\"ibex\"'),\n",
              " (2,\n",
              "  '0.263*\"fmi\" + 0.224*\"ue\" + 0.184*\"dinero\" + 0.086*\"pib\" + 0.048*\"colegios\" + 0.047*\"gaviria\" + 0.046*\"ibex\" + 0.028*\"MEN\" + 0.027*\"deuda\" + 0.009*\"soccer\" + 0.008*\"educacion\" + 0.008*\"messi\" + 0.008*\"ronaldo\" + 0.007*\"campeonato\" + 0.007*\"juego\"')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_model.print_topics(num_words=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX2DQddexJim"
      },
      "source": [
        "Vamos a ver la visualización de lo anterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU4zi3POxOww"
      },
      "source": [
        "# Visualización\n",
        "\n",
        "* La librería llamada \"***pyLDAvis***\" nos permite visualizar las relaciones entre los temas (topic) y dentro de cada tema la importancia de sus palabras (terms).\n",
        "\n",
        "* La parte de visualización de esta librería nos permite ver:\n",
        "    - Parte Izquierda: Visualización de los temas en función de dos componentes (2 Dimensiones)\n",
        "    - Parte Derecha: Seleccionado un Topic, podemos ver las palabras (terms) más relevantes de ese tema y la frecuencia con la que aparecen tanto en el corpus como en el tema.\n",
        "    \n",
        "    * En esta visualización podemos apreciar como se distinguen los tres temas claramente ya que las dos componentes que las definen son claramente distintas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RBdaTgP6xbVn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pyLDAvis\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script f2py.exe is installed in 'C:\\Users\\prestamour\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
            "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.22.4 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Downloading pyLDAvis-3.4.0-py3-none-any.whl (2.6 MB)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: pandas>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.2)\n",
            "Collecting joblib>=1.2.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Collecting funcy\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (61.2.0)\n",
            "Requirement already satisfied: numexpr in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.1)\n",
            "Collecting numpy>=1.22.0\n",
            "  Downloading numpy-1.24.2-cp39-cp39-win_amd64.whl (14.9 MB)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.4->pyLDAvis) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
            "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\prestamour\\appdata\\roaming\\python\\python39\\site-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.4)\n",
            "Installing collected packages: numpy, joblib, funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 joblib-1.2.0 numpy-1.22.4 pyLDAvis-3.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "StpZ_WrUxY3o"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\prestamour\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1569224194158124642926691848\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1569224194158124642926691848_data = {\"mdsDat\": {\"x\": [0.050884813314405246, -0.23711713696952488, 0.18623232365511966], \"y\": [-0.17938316974579058, 0.05734993824320733, 0.1220332315025833], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [35.35304577769353, 32.9150542519056, 31.731899970400868]}, \"tinfo\": {\"Term\": [\"fmi\", \"soccer\", \"ue\", \"deuda\", \"dinero\", \"educacion\", \"ronaldo\", \"messi\", \"colegios\", \"juego\", \"campeonato\", \"pib\", \"MEN\", \"ibex\", \"gaviria\", \"deuda\", \"educacion\", \"colegios\", \"MEN\", \"gaviria\", \"ibex\", \"pib\", \"campeonato\", \"juego\", \"messi\", \"ronaldo\", \"soccer\", \"dinero\", \"ue\", \"fmi\", \"fmi\", \"ue\", \"dinero\", \"ibex\", \"pib\", \"gaviria\", \"colegios\", \"MEN\", \"deuda\", \"campeonato\", \"juego\", \"messi\", \"ronaldo\", \"soccer\", \"educacion\", \"soccer\", \"ronaldo\", \"messi\", \"juego\", \"campeonato\", \"gaviria\", \"MEN\", \"educacion\", \"pib\", \"ibex\", \"colegios\", \"dinero\", \"ue\", \"fmi\", \"deuda\"], \"Freq\": [12.0, 12.0, 10.0, 13.0, 8.0, 14.0, 7.0, 6.0, 12.0, 4.0, 3.0, 5.0, 10.0, 2.0, 8.0, 11.906537055756885, 11.831341334428302, 9.651224963313133, 6.594490519888055, 3.2773207867347978, 0.39761691769736895, 0.6691964521192131, 0.4247562658298212, 0.4135542125805256, 0.4263640243037905, 0.4470700100780163, 0.6781424940209102, 0.43232224600842306, 0.47359258435667506, 0.45661733260326054, 11.786320651875938, 10.012839035145884, 8.25666517387185, 2.068029304173812, 3.847849493618277, 2.1037564416502885, 2.1375835081583885, 1.2414393996560236, 1.2189120355191023, 0.3226275145404015, 0.31281583839001426, 0.35000023474537717, 0.34105711065132827, 0.41012658308532274, 0.35445407847219884, 11.590239210092363, 6.706387557639783, 5.985679799122839, 3.8448461661176694, 3.1034693231042842, 3.5006071826462195, 2.854194370058528, 2.479811216663955, 0.8063245127514826, 0.24639978783279248, 0.9387669536403321, 0.269871572117149, 0.26674225542593033, 0.28595552038487687, 0.2760880847200797], \"Total\": [12.0, 12.0, 10.0, 13.0, 8.0, 14.0, 7.0, 6.0, 12.0, 4.0, 3.0, 5.0, 10.0, 2.0, 8.0, 13.401537175996067, 14.665606629564454, 12.727575425111855, 10.690124289602606, 8.881684411031305, 2.7120460097039736, 5.323370458488972, 3.850853103474507, 4.571216217088209, 6.762044058172007, 7.494514678369127, 12.678508287198596, 8.958858991997422, 10.753173874928489, 12.528893504864074, 12.528893504864074, 10.753173874928489, 8.958858991997422, 2.7120460097039736, 5.323370458488972, 8.881684411031305, 12.727575425111855, 10.690124289602606, 13.401537175996067, 3.850853103474507, 4.571216217088209, 6.762044058172007, 7.494514678369127, 12.678508287198596, 14.665606629564454, 12.678508287198596, 7.494514678369127, 6.762044058172007, 4.571216217088209, 3.850853103474507, 8.881684411031305, 10.690124289602606, 14.665606629564454, 5.323370458488972, 2.7120460097039736, 12.727575425111855, 8.958858991997422, 10.753173874928489, 12.528893504864074, 13.401537175996067], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.3958, -1.4021, -1.6058, -1.9866, -2.6858, -4.7951, -4.2745, -4.7291, -4.7558, -4.7253, -4.6779, -4.2613, -4.7115, -4.6203, -4.6568, -1.3345, -1.4975, -1.6904, -3.0748, -2.4539, -3.0577, -3.0417, -3.5851, -3.6035, -4.9327, -4.9636, -4.8512, -4.8771, -4.6927, -4.8386, -1.3146, -1.8617, -1.9754, -2.4181, -2.6323, -2.5119, -2.716, -2.8566, -3.9801, -5.1656, -3.828, -5.0746, -5.0863, -5.0167, -5.0518], \"loglift\": [15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9215, 0.825, 0.7631, 0.5567, 0.0428, -0.8802, -1.034, -1.1647, -1.363, -1.724, -1.7794, -1.8885, -1.9914, -2.0828, -2.2722, 1.0501, 1.0399, 1.0296, 0.8401, 0.7866, -0.329, -0.6729, -1.0418, -1.2862, -1.3683, -1.5707, -1.8499, -1.9786, -2.32, -2.6114, 1.0581, 1.0367, 1.0259, 0.9748, 0.9321, 0.2168, -0.1727, -0.6295, -0.7395, -1.2507, -1.4591, -2.3546, -2.5488, -2.6321, -2.7346]}, \"token.table\": {\"Topic\": [1, 2, 3, 3, 1, 2, 3, 1, 2, 2, 1, 3, 2, 1, 2, 3, 2, 3, 3, 1, 2, 3, 3, 1, 3, 2], \"Freq\": [0.6548099732393493, 0.09354428189133561, 0.2806328456740068, 0.7790481535878873, 0.7856955992002786, 0.15713911984005574, 0.07856955992002787, 0.8954196703265946, 0.07461830586054956, 0.8929708579123825, 0.8182409567572304, 0.13637349279287173, 0.9577860962216063, 0.33777376690776295, 0.22518251127184197, 0.45036502254368393, 0.7374506158242886, 0.875040647836154, 0.8873056650302259, 0.18785091283762506, 0.7514036513505002, 0.18785091283762506, 0.9340164507521203, 0.07887363224029227, 0.9464835868835073, 0.9299579934548861], \"Term\": [\"MEN\", \"MEN\", \"MEN\", \"campeonato\", \"colegios\", \"colegios\", \"colegios\", \"deuda\", \"deuda\", \"dinero\", \"educacion\", \"educacion\", \"fmi\", \"gaviria\", \"gaviria\", \"gaviria\", \"ibex\", \"juego\", \"messi\", \"pib\", \"pib\", \"pib\", \"ronaldo\", \"soccer\", \"soccer\", \"ue\"]}, \"R\": 15, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1569224194158124642926691848\", ldavis_el1569224194158124642926691848_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1569224194158124642926691848\", ldavis_el1569224194158124642926691848_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1569224194158124642926691848\", ldavis_el1569224194158124642926691848_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(vis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1LFXTy84O_z"
      },
      "source": [
        "# Selección del número óptimo de Topics (coherencia)\n",
        "\n",
        "* Dado que las técnicas de \"*Topic Modeling*\" (tanto LSI como LDA) ***generan automáticamente 'N' temas (Topics)*** a partir de los documentos del corpus ***de forma no supervisada***, tenemos que evaluar de alguna manera si los temas que genera son \"***Coherentes***\" entre sí; es decir, si hay dos o más temas que son tan similares entre sí que podrían formar un tema o si hay temas que son muy genéricos y que podrían dividirse en dos o más temas.\n",
        "\n",
        "* Este es un problema común que también tenemos las personas a la hora de asignar un tema a un texto ya que se trata de una tarea que en ocasiones puede ser muy subjetiva.\n",
        "\n",
        "* Por esta razón es necesario cuantificar un nivel de ***Coherencia*** sobre la segmentación realizada.\n",
        "\n",
        "* Para hacer una analogía con Clustering, la ***Coherencia*** en el Topic Modeling viene a ser como la ***Inercia*** en el K-Means.\n",
        "\n",
        "* La ***Coherencia*** es por tanto una medida que ***nos sirve para ver lo bien o mal que están definidos los temas (Topics) por sus palabras (Terms) más representativas del Topic***.\n",
        "\n",
        "* Para más información ver el siguiente artículo: http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
        "\n",
        "\n",
        "### ¿Como se calcula la Coherencia?\n",
        "\n",
        "\n",
        "* La coherencia de un modelo se calcula dadas las 'N' palabras más relevantes de un tema (Topic) como:\n",
        "\n",
        "\n",
        "$$ coherence = \\sum_{i>j} score(w_{i},w_{j})$$\n",
        "\n",
        "\n",
        "* Siendo w<sub>i</sub> y w<sub>j</sub> dos pares de palabras relevantes del tema (Topic).\n",
        "\n",
        "\n",
        "* Existen dos métodos para el cálculo del ***score*** de la coherencia que son:\n",
        "    - Extrinsic UCI measure\n",
        "    - Intrinsic UMass measure\n",
        "   \n",
        "   \n",
        "* Antes de explicar como se calcula el score definimos:\n",
        "\n",
        "    - **D**: Número de documentos del corpus.\n",
        "    - **D(w<sub>i</sub>)**: Número de documentos en el que aparece la palabra w<sub>i</sub> en el corpus.\n",
        "    - **D(w<sub>i</sub>, w<sub>j</sub>)**: Número de documentos en el que aparecen conjuntamente las palabras w<sub>i</sub> y w<sub>j</sub> en el corpus.\n",
        "    - **p(w<sub>i</sub>)**: Probabilidad de que aparezca la palabra w<sub>i</sub> en un documento del corpus:\n",
        "    \n",
        "    $$p(w_{i}) = \\frac{D(w_{i})}{D}$$\n",
        "    \n",
        "    - **p(w<sub>i</sub>, w<sub>i</sub>)**: Probabilidad de que aparezcan conjuntamente las palabras w<sub>i</sub> y w<sub>j</sub> en un documento del corpus:\n",
        "    \n",
        "    $$p(w_{i}, w_{j}) = \\frac{D(w_{i}, w_{j})}{D}$$\n",
        "    \n",
        "* ***Score: Extrinsic UCI measure***\n",
        "    \n",
        "    $$score_{c\\_uci} (w_{i}, w_{j}) = log \\frac{p(w_{i},w_{j})}{p(w_{i}) p(w_{j})}$$\n",
        "\n",
        "\n",
        "* ***Score: Intrinsic UMass measure***\n",
        "    \n",
        "    $$score_{c\\_mass} (w_{i}, w_{j}) = log \\frac{D(w_{i},w_{j}) + 1}{D(w_{i})}$$\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTjbKVDYyDr_"
      },
      "source": [
        "# Taller para iniciar en clase\n",
        "\n",
        "\n",
        "* Vamos a considerar el siguiente conjunto de documentos ***obtener los temas (Topics) de una serie de artículos (noticias)*** que está etiquetados con un tema (el corpus tiene 20 temas).\n",
        "\n",
        "- El fichero en formato Json contiene una serie de documento en los que le asigna una temática.\n",
        "\n",
        "- Cada elemento del Json contiene:\n",
        "    - **content**: Contenido del artículo\n",
        "    - **target**: Identificador del target\n",
        "    - **target_names**: Nombre del target\n",
        "\n",
        "\n",
        "* ***IMPORTANTE***: *Esto es aprendizaje no supervisado, por lo que no tenemos que tener en cuentas los temas en los que alguien (un humano experto) ha clasificado estos textos. La idea del ejercicio es la de obtener los temas distintos de los que hablan los artículos (***Clusterizar artículos***) y nos es útil saber a priori el número de temas distintos que puede tener, pero en ningún caso el target de los artículos entraria al algoritmo de aprendizaje (LDA en este caso)*\n",
        "\n",
        "* Para realizar este ejercicio se seguirán los siguientes pasos\n",
        "\n",
        "1. Carga de datos\n",
        "2. Exploración de los datos y entendimiento del conjunto de datos\n",
        "3. Interprete el siguiente código\n",
        "\n",
        "```\n",
        "df.groupby(['target', 'target_names']).count()\n",
        "```\n",
        "4. Para la Normalización utilizar ***spaCy*** y realizar las siguientes acciones en una sola función\n",
        "\n",
        "    4.1. Pasar las frases a minúsculas.\n",
        "\n",
        "    4.2. Eliminar los signos de puntuación.\n",
        "\n",
        "    4.3. Eliminar las palabras con menos de 3 carácteres.\n",
        "\n",
        "    4.4. Eliminar las palabras con mas de 12 carácteres.\n",
        "\n",
        "    4.5. Eliminar las Stop-Words.\n",
        "\n",
        "    4.6. Eliminar los emails\n",
        "\n",
        "    4.7. Eliminar los saltos de línea\n",
        "\n",
        "    4.8. Eliminar las comillas simples\n",
        "\n",
        "    4.9. Filtrar las palabras que no sean Nombre, Adjetivo, Verbo o Adverbio\n",
        "\n",
        "    4.10. Pasar la palabra a su lema\n",
        "\n",
        "5. Crear del diccionario y la bolsa de palabras\n",
        "\n",
        "    5.1 Corpus tokenizado: \"*documents_tok*\"\n",
        "\n",
        "    5.2 Diccionario: \"*dictionary*\"\n",
        "\n",
        "    5.3 Corpus: \"*corpus*' que es la bolsa de palabras de gensim\n",
        "\n",
        "6. Creacción del modelo\n",
        "\n",
        "    6.1 Crear un modelo con 20 temas\n",
        "\n",
        "    6.2 Utilice la instrucción \"chunksize=100\". ¿Qué efecto tiene?\n",
        "\n",
        "7. Visualización. \n",
        "\n",
        "    7.1 Visualizar los resultados con la librería de *pyLDAvis*\n",
        "\n",
        "    7.2 ¿Qué puede concluir de la visualización?\n",
        "\n",
        "8. ¿Qué sucede si seleccionó 12, 15, 17 temas? Haga la visualización en estos casos. ¿Cuál es mejor?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4MlVZrSF0V1e"
      },
      "outputs": [],
      "source": [
        "url= \"https://raw.githubusercontent.com/Fabian830348/Bases_Datos/master/base_LDA.json\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d7V_8aPtKZQY",
        "0shdLpG-Pwi7",
        "dVRqBuYuRUGr",
        "WE0al5K6Rize",
        "xipA6oi3SJEu"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
