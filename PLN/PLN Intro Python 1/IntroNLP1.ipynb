{"cells":[{"cell_type":"markdown","metadata":{"id":"y4HtffMo3eev"},"source":["# Introducción al Procesamiento del Lenguaje Natural, con Python\n","\n","# Contenido\n","\n","#### Tema 1: Introducción\n","\n","\n","* ¿Qué es un Lenguaje?\n","\n","\n","* ¿Qué es el Procesamiento del Lenguaje Natural?\n","\n","\n","* Herramientas en Python para NLP:\n","    - NLTK\n","    - SpaCy\n","    - Gensim\n","    - Scikit\n","    - TensorFlow-Keras\n","\n","\n","#### Tema 2: NLP - Conceptos y Preprocesamiento de texto\n","\n","\n","* Conceptos:\n","\n","    - Corpus\n","    - Bag of Words (BoW)\n","    - Tokenización\n","    - N-Grammas\n","    - Stemming\n","    - Lematización\n","    - Stop-Words\n","    - Parts of Speech (PoS)\n","    - Named Entity Recognition (NER)\n","\n","\n","* Normalización de textos: Preprocesamiento\n","\n","\n","#### Tema 3: Analisis Automático de texto subjetivo (Clasificación de textos)\n","\n","\n","* Introducción: Clasificación de textos con Naive Bayes\n","\n","\n","* Clasificación de textos: Algoritmos de aprendizaje para la clasificación\n","\n","\n","* Clasificación de textos: Redes Neuronales\n","\n","\n","#### Tema 4: Topic Modeling (Clustering)\n","\n","\n","* LSI: Latent Semantic Index\n","\n","\n","* LDA: Latent Dirichlet Allocation\n","\n","\n","* Visialización: pyLDAvis\n","\n","\n","#### Tema 5: Uso de modelos pre-entrenado en \"Hugging Face\" (Transformers)\n","\n","\n","* Clasificación\n","\n","\n","* Traducción\n","\n","\n","* Resumenes de textos\n","\n","\n","#### Tema 6: Introducción a GPT3\n","\n","\n","<hr>\n","\n","\n","# Tema 1: Introducción\n","\n","\n","## ¿Qué es un Lenguaje?\n","\n","\n","* Un Lenguajes es un conjunto potencialmente infinito de oraciones y sentencias de palabras construidas mediante reglas gramaticales, foneticas y de significación que rigen el propio lenguaje.\n","\n","\n","* Nos encontramos con 3 tipos de lenguajes:\n","<span></span><br><br>\n","    - ***Lenguaje Natural***: Lengua o idioma que nace espontáneamente de un grupo de hablantes por la necesidad de establecer comunicación verbal. Ejm: Ingles, Castellano, Frances, Italiano, etc.\n","<span></span><br><br>\n","    - ***Lenguaje Formal***: Lenguajes diseñados para un ámbito de aplicación concreto, que se definen de manera precisa y libre de ambigüedad. Ejm: Matemático, Lógico, Musical, Programación (C, Java, Python, R, Scala, etc.)\n","<span></span><br><br>\n","    - ***Lenguaje Artificial***: Lenguajes diseñados antes de ser usados por sus parlantes. Es una mezcla entre los lenguajes naturales y formales. Ejm: Klingon.\n","\n","\n","\n","## ¿Qué es el Procesamiento del Lenjuaje Natural?\n","\n","\n","* El ***Procesamiento del Lenguaje Natural*** (NLP) es un campo que combina la ***Informática***, la ***Inteligencia Artificial*** y la ***Lingüística***; que tiene como objetivo, tratar la interacción entre los lenguajes humanos (lenguajes naturales) y los dispositivos informáticos.\n","\n","\n","* El NLP abarca los siguientes campos:\n","    - Recuperación de información\n","    - Extracción y categorización de información\n","    - Análisis automático de texto subjetivo (Análisis de sentimientos)\n","    - Traducción automática\n","    - Generación del lenguaje\n","    - Questions & Answering (Chatbots)\n","\n","\n","## De la *Lingüística* al *Procesamiento del Lenguaje Natural*\n","\n","### - Lingüística\n","\n","\n","* La ***lingüística*** es el estudio científico del lenguaje, incluyendo su gramática, semántica y fonética.\n","\n","\n","* En términos generales, un ***lingüista*** es cualquier persona que estudia un idioma.\n","\n","\n","### - Lingüística computacional\n","\n","\n","* La lingüística computacional es el estudio de la lingüística utilizando las herramientas de la informática. \n","\n","\n","### - Procesamiento estadístico del lenguaje natural\n","\n","\n","* La lingüística computacional también se conoce con el nombre de Procesamiento del Lenguaje Natural, para reflejar el enfoque más ingenieril o empírico de los métodos estadísticos aplicados a la Lingüistica. \n","\n","\n","* El dominio estadístico del campo, lleva a menudo a que el ***NLP*** sea descrito como ***Procesamiento Estadístico del Lenguaje Natural***, para distanciarse (en la definición) de los métodos clásicos de la lingüística computacional.\n","\n","\n","### - Procesamiento del Lenguaje natural\n","\n","\n","* Campo que combina la ***Informática***, la ***Inteligencia Artificial*** y la ***Lingüística***; que tiene como objetivo, tratar la interacción entre los lenguajes humanos (lenguajes naturales) y los dispositivos informáticos.\n","\n","\n","## Herramientas en Python para el NLP\n","\n","\n","* Aunque existen bastante librería en Python destinadas al Procesamiento del Lenguaje Natural o a resolver determinadas partes del NLP, mostramos a continuación una serie de librería que vamos a utilizar en este curso:\n","<span></span><br><br>\n","    - ***NLTK*** (https://www.nltk.org/): Es una librería desarrollada por Steven Bird y Edward Loper para el NLP (principalmente en Inglés) que incorpora muchas funcionalidades como, corpus, recursos léxicos, algoritmos de aprendizaje para el NLP, etc.\n","<span></span><br><br>\n","    - ***SpaCy*** (https://spacy.io/): Es una librería para el NLP incorpora funcionalidades como Tokenización, Lematización, PoS, NER, etc. en varios idiomas. A diferencia de NLTK que tienen fines de caracter didáctico, SpaCy esta pensado para explotarlo en entornos productivos.\n","<span></span><br><br>\n","    - ***Gensim*** (https://radimrehurek.com/gensim): Es una librería desarrollada por el Checo Radim Řehůřek, Ph.D, que tiene implementadas; entre otras cosas, algoritmos como el LSI y el LDA para la detección de tópicos (Topic Modeling)\n","<span></span><br><br>\n","    - ***Scikit*** (https://scikit-learn.org/): Es una librería que tiene implementada multitud de algoritmos de aprendizaje (regresión, clasificación, cluterización, reducción de la dimensionalidad) y funcionalidades para trabajar con estos algoritmos.\n","<span></span><br><br>\n","    - ***TensorFlow-Keras*** (https://www.tensorflow.org/): Es una librería desarrollada por Google para trabajar con Redes Neuronales (MLP, CNN, RNN). La versión 2 de TensorFlow hace uso del API de Keras para un desarrollo más sencillo.\n","    \n","    \n","## Bibliografía recomendada para NLP (en Inglés)\n","\n","\n","1. **Natural Language Processing with Python** de Steven Bird, Ewan Klein y Edward Loper. O'Reilly Media. Julio 2009.\n","\n","2. **Applied Text Analysis with Python**, de Benjamin Bengfort, Rebecca Bilbro y Tony Ojeda. O'Reilly Media. Junio 2018.\n","\n","3. **Natural Language Processing Crash Course for Beginners**, de AI Publishing. Agosto 2020.\n","\n","4. **Transformers for Natural Language Processing**,  de Denis Rothman. Packt Publishing. Enero 2021.\n","    "]},{"cell_type":"markdown","source":["# 01 - Introducción a la librería NLTK\n","\n","\n","* NLTK (https://www.nltk.org/) es una librería para Python, usada para el análisis y la manipulación del lenguaje natural.\n","\n","\n","* Se instala bien con el gestor de paquetes \"pip\" o con \"conda\" en caso de utilizarlo. Para instalarlo con pip o conda se realiza de la siguiente manera respectivamente:\n","\n","```\n",">> pip install nltk\n",">> conda install nltk\n","```\n","\n","<hr>\n","\n","## 1.- Instalación y descargar de las bases de datos\n","\n","* NLTK utiliza una serie de bases de datos léxicas para la manipulación del lenguaje natural.\n","\n","\n","* También dispone de una una serie de corpus (colección de textos) que nos podemos descargar para \"jugar\" con ellos.\n","\n","\n","* Para descargarnos las bases de datos y los corpus realizaremos lo siguiente:\n","    1. Importar la librería nltk\n","    2. llamar a al método \"download\"<sup>(*)</sup>\n","    3. Aparecerá una ventana emergente para seleccionar todo lo que NLTK nos permite descargar\n","    \n","    \n","###### (*): Si utilizas un MAC es posible que al ejecutar el método \"download()\" haga un logout de la sesión. Para evitarlo y para que se descargue todo el contenido, es necesario pasarle al método \"download\" como parámetros aquello que nos queramos descargar, en nuestro caso todo:\n","\n","```\n",">> nltk.download('all')\n","```"],"metadata":{"id":"sFdx4vh13k__"}},{"cell_type":"code","source":["import nltk\n","nltk.download(\"all\")\n"],"metadata":{"id":"DcfMJDI-3qzZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.- Corpus\n","\n","\n","* Un ***Corpus*** (en Latín \"*Cuerpo*\") dentro del contexto del NLP se refiere a una colección de textos como puede ser un conjunto de artítulo periodísticos, libros, críticas, tweets, etc.\n","\n","\n","* NLTK dispone de una serie de ***Corpus*** con los que poder trabajar y realizar pruebas.\n","\n","\n","* Algunos de los ***corpus*** que pueden ser de interés didáctico son los siguientes:\n","\n","|Corpus|Content|\n","|---|---|\n","|Brown Corpus|15 genres, 1.15M words, tagged, categorized|\n","|CESS Treebanks|1M words, tagged and parsed (Catalan, Spanish)|\n","|Gutenberg (selections)|18 texts, 2M words|\n","|Inaugural Address Corpus|U.S. Presidential Inaugural Addresses (1789–present)|\n","|Movie Reviews|2k movie reviews with sentiment polarity classification|\n","|Reuters Corpus|1.3M words, 10k news documents, categorized|\n","|Stopwords Corpus|2,400 stopwords for 11 languages|\n","|WordNet 3.0 (English)|145k synonym sets|\n","\n","\n","* Para más información relativa a los corpus ir al siguiente enlace: http://www.nltk.org/howto/\n","\n","\n","<hr>"],"metadata":{"id":"9mjDc70C3-Cq"}},{"cell_type":"markdown","source":["### 2.1.- Manejo de Corpus (funcionalidades)\n","\n","Dentro de NLTK podemos encontrarnos diferentes tipos de Corpus que podrían clasificarse en:\n","\n","* Textos planos: como el corpus de *Gutenberg*\n","* Textos categorizados: como el corpus de *Bronwn* (15 generos)\n","* Textos multicategóricos: como el corpus de *Reuters* (1 documentos, varias categorias)\n","* Textos temporales: como el corpus *Inaugural Address Corpus*, discursos presidenciales a lo largo de la historia\n","\n","Para el manejo de estos corpus NLTK nos ofrece las siguientes funciones:\n","\n","|Example|Description|\n","|---|---|\n","|fileids()|the files of the corpus|\n","|fileids([categories])|the files of the corpus corresponding to these categories|\n","|categories()|the categories of the corpus|\n","|categories([fileids])|the categories of the corpus corresponding to these files|\n","|raw()|the raw content of the corpus|\n","|raw(fileids=[f1,f2,f3])|the raw content of the specified files|\n","|raw(categories=[c1,c2])|the raw content of the specified categories|\n","|words()|the words of the whole corpus|\n","|words(fileids=[f1,f2,f3])|the words of the specified fileids|\n","|words(categories=[c1,c2])|the words of the specified categories|\n","|sents()|the sentences of the whole corpus|\n","|sents(fileids=[f1,f2,f3])|the sentences of the specified fileids|\n","|sents(categories=[c1,c2])|the sentences of the specified categories|\n","|abspath(fileid)|the location of the given file on disk|\n","|encoding(fileid)|the encoding of the file (if known)|\n","|open(fileid)|open a stream for reading the given corpus file|\n","|root|if the path to the root of locally installed corpus|\n","|readme()|the contents of the README file of the corpus|\n","\n","### 2.1.1.- Ejemplo con el corpus de Gutenberg\n","\n","**1. ¿Que ficheros componen el corpus?**"],"metadata":{"id":"6VaNuDEa4PBs"}},{"cell_type":"code","source":["from nltk.corpus import gutenberg\n","gutenberg.fileids()"],"metadata":{"id":"_myh1I0D4P1I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2. ¿Cual es el contenido del fichero \"blake-poems.txt\"?**\n","\n","(Por lectura mostramos solo los 300 primeros caracteres)"],"metadata":{"id":"Qt2Y6Xq-4Zfs"}},{"cell_type":"code","source":["contenido = gutenberg.raw(\"blake-poems.txt\")\n","contenido[:300]"],"metadata":{"id":"JHnnFiKE4ZNI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para cargar alguno de estos libros en variables y poder manipularlos directamente, podemos utilizar varios métodos.\n","\n","- `gutenberg.raw` recupera el texto como una única cadena de caracteres.\n","- `gutenberg.words` recupera el texto tokenizado en palabras. El método devuelve una lista palabras.\n","- `gutenberg.sents` recupera el texto segmentado por oraciones. El método devuelve una lista de oraciones. Cada oración es a su vez una lista de palabras.\n","- `gutenberg.paras` recupera el texto  segmentado por párrafos. El método devuelve una lista de párrafos.  Cada párrafo es una lista de oraciones, cada oración es a su vez una lista de palabras."],"metadata":{"id":"mvQdKJ9340r4"}},{"cell_type":"code","source":["# cargo la vesión 'cruda' de un par de libros. Como son libros del Proyecto Gutenberg, se trata de ficheros en texto plano\n","alice = gutenberg.raw(\"carroll-alice.txt\")\n","print(alice[:200]) # imprimo los primeros 200 caracteres del libro de Alicia\n","\n","bible = gutenberg.raw(\"bible-kjv.txt\")\n","print(bible[:200]) # imprimo los primeros 200 caracteres de la Biblia"],"metadata":{"id":"Vcjy1gG442hM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["De cada uno de los ficheros mostramos: \n","\n","- Número de caracteres \n","\n","- Número de palabras\n","\n","- Número de frases \n"," \n","- Número de medio de caracteres por palabra \n"," \n","- Número medio de palabras por frase\n"," \n","- Diversidad léxica (número de palabras / palabras distintas del texto)"],"metadata":{"id":"28J8dTIY4_6A"}},{"cell_type":"code","source":["for file in gutenberg.fileids():\n","    num_chars = len(gutenberg.raw(file))\n","    num_words = len(gutenberg.words(file))\n","    num_sents = len(gutenberg.sents(file))\n","    avg_chars_words = int(num_chars/num_words)\n","    avg_words_sents = int(num_words/num_sents)\n","    lexical_diversity = int(num_words/num_words_distinct)\n","    print(\"{num_chars:<10} {num_words:<10} {num_sents:<10} {avg_chars_words:<10} {avg_words_sents:<10} {lexical_diversity:<10} {file:<10}\"\n","          .format(num_chars=num_chars, num_words=num_words, num_sents=num_sents, avg_chars_words=avg_chars_words,\n","                  avg_words_sents = avg_words_sents, lexical_diversity=lexical_diversity, file=file))"],"metadata":{"id":"nJ1Runtb5KIz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ejemplo con el corpus de Brown\n","\n","Este es un corpus que contiene una serie de textos categorizados (o tageados) con un tipos de genero\n","\n","1. ¿Cuales son las categorias del corpus de Brown?"],"metadata":{"id":"kHSJHD1K6wwm"}},{"cell_type":"code","source":["from nltk.corpus import brown\n","brown.categories()"],"metadata":{"id":"wdQ-80KJ6vDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***2. ¿Qué ficheros componen la categoría de noticias (news)?*** (por legibilidad solo mostramos 5)"],"metadata":{"id":"Kr4T4Luq618g"}},{"cell_type":"code","source":["brown.fileids(['news'])[0:5]"],"metadata":{"id":"LWr3CU-x60m0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***3.¿Que categorias corresponden al fichero \"ca01\"?***"],"metadata":{"id":"8Qi6UBvR67EI"}},{"cell_type":"code","source":["brown.categories(fileids=['ca01'])"],"metadata":{"id":"bFb5HR6G67rY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***4.¿Que palabras corresponden a la categoria humor?***"],"metadata":{"id":"8qHBTS287A_r"}},{"cell_type":"code","source":["brown.words(categories='humor')"],"metadata":{"id":"L8cm8k5P7AyL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.- WordNet\n","\n","* ***WordNet*** es un diccionario semántico y jerárquico en Ingles compuesto por una 155k palabras y 117K sinónimos.\n","\n","\n","* De forma jerarquica, esta estructurado de tal manera que hay una serie de palabras llamadas \"***unique beginers***\" o \"*root synsets*\" que son palabras que definen \"conceptos\" muy generales y a partir de esos conceptos generales engloban una serie de palabras pertenecientes a ese concepto. Veamos el siguiente ejemplo:\n","\n","* En este ejemplo vemos como un \"*camión*\" (truck) esta definido como un \"*vehiculo motorizado*\" (motor vehicle) y este a su vez esta definido por otra palabra de nivel conceptual superior, hasta llegar a un muy alto nivel de palabra que lo define como un \"*artefacto*\" (artefact).\n","\n","\n","* Este seria (\"a grandes rasgos\") como está organizado este diccionario, de tal manera que permite obtener de una palabra cosas como:\n","    * Sinónimos\n","    * Antónimos\n","    * Hipérnimos\n","    * Hipónimos\n","    * Merónimos\n","    * Holónimos\n","    * Etc.\n","    \n","\n","Veamos a continuación un ejemplo con la palabra \"motorcar\" y como nos daría una lista de sinónimos (synset) de esa palabra con la función \"synsets()\""],"metadata":{"id":"kclW1jgy7KT_"}},{"cell_type":"code","source":["from nltk.corpus import wordnet as wn\n","wn.synsets('motorcar')"],"metadata":{"id":"bemRLHtf7Jzf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* En este caso nos devuelve una lista de sinónimos (synset), que serian los \"nodos\" del diccionario jerarquico a partir del cual se relaciona esa palabra. Para este ejemplo solo nos ha dado un sinónimo.\n","\n","* A partir del \"nodo\" 'car.n.01' vamos a:\n","    * Obtener su definición\n","    * Obtener los lemas de sus sinónimos (de la palabra car no de la palabra motorcar)"],"metadata":{"id":"w-rVRv897bBa"}},{"cell_type":"code","source":["definicion = wn.synset('car.n.01').definition()\n","sinonimos = wn.synset('car.n.01').lemma_names()\n","\n","print('Definición: ' + definicion)\n","print('Sinónimos: ' + str(sinonimos))"],"metadata":{"id":"3W45I3fk7Zql"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Relación semántica entre palabras\n","\n","* Otro tema interesante que tenemos con ***WordNet*** es que nos permite ver la relación semáncia o la similaridad que hay entre palabras veamos por ejemplo la similaridad entre las siguientes palabras:\n","\n","    * car\n","    * truck\n","    * dog\n","\n","* Primero obtenemos alguno de los \"nodos\" de la palabra (el primero)\n","* Comparamos la similaridad \"nodo\" con \"nodo\""],"metadata":{"id":"HcRhSrb_7omi"}},{"cell_type":"code","source":["car = wn.synsets('car')[0]\n","truck = wn.synsets('truck')[0]\n","dog = wn.synsets('dog')[0]\n","\n","print('Similaridad entre Coche y Camión: ' + str(car.path_similarity(truck)))\n","print('Similaridad entre Coche y Perro: ' + str(car.path_similarity(dog)))"],"metadata":{"id":"BdQ9PaPe7oYz"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}