{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RS-stql-8yW"
   },
   "source": [
    "# Universidad del Rosario\n",
    "# Procesamiento de Lenguaje Natural\n",
    "# Caso de estudio 2 corte 2\n",
    "# Fabián Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7i33H7jq8K0E"
   },
   "source": [
    "# Caso corte 2\n",
    "\n",
    "- Para entregar antes del día martes 18 de abril a las 18:00. En grupos de dos integrantes\n",
    "\n",
    "- Cargar el .pynb en la carpeta de las aulas virtuales\n",
    "\n",
    "- Los avances del caso se realizará el día 12 de abril en clase y se evaluarán los avances y el trabajo en la clase.\n",
    "\n",
    "- El trabajo completo se cargará de acuerdo a las anteriores instrucciones.\n",
    "\n",
    "Considere el siguiente conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "myJMUhL98Rlw"
   },
   "outputs": [],
   "source": [
    "url= \"https://raw.githubusercontent.com/Fabian830348/Bases_Datos/master/base_LDA.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este es utilizado para español\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "# Este es utilizado oara ingles\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "snZ7_Ywk8E6i"
   },
   "source": [
    "# PUNTO 1\n",
    "\n",
    "* Considere el siguiente conjunto de documentos ***obtener los temas (Topics) de una serie de artículos (noticias)*** que está etiquetados con un tema (el corpus tiene 20 temas).\n",
    "\n",
    "- El fichero en formato .Json contiene una serie de documento en los que le asigna una temática.\n",
    "\n",
    "- Cada elemento del Json contiene:\n",
    "\n",
    "    - **content**: Contenido del artículo\n",
    "    - **target**: Identificador del target\n",
    "    - **target_names**: Nombre del target\n",
    "\n",
    "\n",
    "* ***NOTA***: *Ya que vamos a realizar un ejercicio de aprendizjae no supervisado, no debemos tener en cuentas los temas en los que alguien (un humano experto) ha clasificado estos textos. La idea del ejercicio es obtener los temas distintos de los que hablan los artículos (***Clusterizar artículos***). En este sentido es útil saber a priori el número de temas distintos que puede tener, pero en ningún caso el target de los artículos entraria al algoritmo de aprendizaje*\n",
    "\n",
    "* Para realizar este ejercicio se seguirán los siguientes pasos\n",
    "\n",
    "5. Crear del diccionario y la bolsa de palabras\n",
    "\n",
    "    5.1 Corpus tokenizado: \"*documents_tok*\"\n",
    "\n",
    "    5.2 Diccionario: \"*dictionary*\"\n",
    "\n",
    "    5.3 Corpus: \"*corpus*' que es la bolsa de palabras de gensim\n",
    "\n",
    "6. Creacción del modelo\n",
    "\n",
    "    6.1 Crear un modelo con 20 temas\n",
    "\n",
    "    6.2 Utilice la instrucción \"chunksize=100\". ¿Qué efecto tiene?\n",
    "\n",
    "7. Visualización. \n",
    "\n",
    "    7.1 Visualizar los resultados con la librería de *pyLDAvis*\n",
    "\n",
    "    7.2 ¿Qué puede concluir de la visualización?\n",
    "\n",
    "8. ¿Qué sucede si seleccionó 12, 15, 17 temas? Haga la visualización en estos casos. ¿Cuál es mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Cargas Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>From: brown@ftms.UUCP (Vidiot)\\nSubject: Re: p...</td>\n",
       "      <td>5</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>From: markm@bigfoot.sps.mot.com (Mark Monninge...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>From: fmsalvat@eos.ncsu.edu (FRANK MICHAE SALV...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>From: erics@netcom.com (Eric Smith)\\nSubject: ...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10824</th>\n",
       "      <td>From: avg@rodan.UU.NET (Vadim Antonov)\\nSubjec...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  target  \\\n",
       "2362   From: brown@ftms.UUCP (Vidiot)\\nSubject: Re: p...       5   \n",
       "6854   From: markm@bigfoot.sps.mot.com (Mark Monninge...       7   \n",
       "11123  From: fmsalvat@eos.ncsu.edu (FRANK MICHAE SALV...      10   \n",
       "7235   From: erics@netcom.com (Eric Smith)\\nSubject: ...       9   \n",
       "10824  From: avg@rodan.UU.NET (Vadim Antonov)\\nSubjec...      11   \n",
       "\n",
       "             target_names  \n",
       "2362       comp.windows.x  \n",
       "6854            rec.autos  \n",
       "11123    rec.sport.hockey  \n",
       "7235   rec.sport.baseball  \n",
       "10824           sci.crypt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: markm@bigfoot.sps.mot.com (Mark Monninger)\\nSubject: Re: Auto air conditioning without Freon\\nNntp-Posting-Host: 223.250.10.7\\nReply-To: rapw20@email.sps.mot.com\\nOrganization: SPS\\nDistribution: usa\\nLines: 20\\n\\nIn article <1993Apr15.222600.11690@research.nj.nec.com>  \\nbehanna@syl.nj.nec.com (Chris BeHanna) writes:\\n>  ...\\n> \\tSeveral chemists already have come up with several substitutes for\\n> R12.  You don't hear about them because the Mobile Air Conditioning  \\nSociety\\n> (MACS), that is, the people who stand to rake in that $300 to $1000 per\\n> retrofit per automobile, have mounted an organized campaign to squash  \\nthose\\n> R12 substitutes out of existence if not ban them altogether (on very  \\nshaky\\n> technical grounds, at best, on outright lies at worst).\\n>  ...\\n\\nNow, I'm not saying you're wrong because I know that the R-12 substitutes  \\nexist, but this sounds a lot like the 200mpg carbs that the oil companies  \\nkeep us all from getting.\\n\\nMark\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content.iloc[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Exploración de los datos y entendimiento del conjunto de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Interpretación del siguiente codigo\n",
    "```\n",
    "df.groupby(['target', 'target_names']).count()\n",
    "```\n",
    "\n",
    "**El siguiente codigo nos agrupa por la etiqueta y nos dice cuantas noticias hay por cada una de las etiquetas realizando un conteo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>comp.os.ms-windows.misc</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>comp.sys.ibm.pc.hardware</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>rec.autos</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>rec.motorcycles</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>rec.sport.baseball</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>rec.sport.hockey</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>sci.crypt</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>sci.electronics</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>sci.med</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>sci.space</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>talk.politics.guns</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>talk.politics.mideast</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>talk.politics.misc</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 content\n",
       "target target_names                     \n",
       "0      alt.atheism                    92\n",
       "1      comp.graphics                 120\n",
       "2      comp.os.ms-windows.misc       122\n",
       "3      comp.sys.ibm.pc.hardware      138\n",
       "4      comp.sys.mac.hardware         122\n",
       "5      comp.windows.x                135\n",
       "6      misc.forsale                  145\n",
       "7      rec.autos                     137\n",
       "8      rec.motorcycles               118\n",
       "9      rec.sport.baseball            125\n",
       "10     rec.sport.hockey              140\n",
       "11     sci.crypt                     152\n",
       "12     sci.electronics               128\n",
       "13     sci.med                       124\n",
       "14     sci.space                     153\n",
       "15     soc.religion.christian        137\n",
       "16     talk.politics.guns            105\n",
       "17     talk.politics.mideast         129\n",
       "18     talk.politics.misc             91\n",
       "19     talk.religion.misc             87"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Este codigo nos indica cuantas noticias hay en cada una de las etiquetas.\n",
    "df.groupby(['target', 'target_names']).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Para la Normalización utilizar ***spaCy*** y realizar las siguientes acciones en una sola función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    #Identificar el idioma\n",
    "    idioma = detect(text)\n",
    "    #4.1. Pasar las frases a minúsculas.\n",
    "    text = text.lower()\n",
    "    #4.6. Eliminar los emails  \\S*@\\S*\\s\n",
    "    #\\S Identifica caracteres que no son espacio\n",
    "    #* Lo realiza continuamente\n",
    "    #\\s Identifica espacios\n",
    "    text = re.sub(\"\\S*@\\S*\\s\",\"\",text)\n",
    "    #print(text)\n",
    "    #4.2. Eliminar los signos de puntuación.\n",
    "    #4.7. Eliminar los saltos de línea\n",
    "    #4.8. Eliminar las comillas simples\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\",\" \", text) \n",
    "    #print(text)\n",
    "    # Tokenización\n",
    "    if idioma == \"en\":\n",
    "        doc = nlp_en(text)\n",
    "    else:\n",
    "        doc = nlp_es(text)\n",
    "    #Realizamos una lista donde tenemos las palabras tokenizadas, su lema, su longitud\n",
    "    # su tag y si son o no palabras de parada.\n",
    "    resultado = [[tk.text, len(tk.text),tk.lemma_, tk.pos_, tk.is_alpha, tk.is_stop] for tk in doc]\n",
    "    # 4.5. Eliminar las Stop-Words.\n",
    "    resultado = [lista for lista in resultado if lista[5] == False]\n",
    "    #4.3. Eliminar las palabras con menos de 3 carácteres.\n",
    "    #4.4. Eliminar las palabras con mas de 12 carácteres.\n",
    "    resultado = [lista for lista in resultado if (lista[1] <12) and (lista[1] > 3)]\n",
    "    # 4.9. Filtrar las palabras que no sean Sustantivo, Adjetivo, Verbo o Adverbio.\n",
    "    resultado = [lista for lista in resultado if (lista[3] == 'NOUN') or (lista[3] == 'ADJ') or (lista[3] == 'ADV') or (lista[3] == 'VERB')]\n",
    "    #4.10. Pasar la palabra a su lema\n",
    "    #Tomamos los lemas de cada una de las palabras de la lista despues de la limpieza.\n",
    "    result = []\n",
    "    for i in resultado:\n",
    "        result.append(i[2])\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject', 'auto', 'freon', 'nntp', 'post', 'host', 'reply', 'line', 'article', 'write', 'chemist', 'come', 'substitute', 'hear', 'mobile', 'society', 'mac', 'people', 'stand', 'rake', 'retrofit', 'automobile', 'mount', 'organize', 'campaign', 'squash', 'substitute', 'existence', 'altogether', 'shaky', 'technical', 'ground', 'good', 'outright', 'lie', 'bad', 'say', 'wrong', 'know', 'substitute', 'exist', 'sound', 'carb', 'company', 'get', 'mark']\n"
     ]
    }
   ],
   "source": [
    "a = \"From: markm@bigfoot.sps.mot.com (Mark Monninger)\\nSubject: Re: Auto air conditioning without Freon\\nNntp-Posting-Host: 223.250.10.7\\nReply-To: rapw20@email.sps.mot.com\\nOrganization: SPS\\nDistribution: usa\\nLines: 20\\n\\nIn article <1993Apr15.222600.11690@research.nj.nec.com>  \\nbehanna@syl.nj.nec.com (Chris BeHanna) writes:\\n>  ...\\n> \\tSeveral chemists already have come up with several substitutes for\\n> R12.  You don't hear about them because the Mobile Air Conditioning  \\nSociety\\n> (MACS), that is, the people who stand to rake in that $300 to $1000 per\\n> retrofit per automobile, have mounted an organized campaign to squash  \\nthose\\n> R12 substitutes out of existence if not ban them altogether (on very  \\nshaky\\n> technical grounds, at best, on outright lies at worst).\\n>  ...\\n\\nNow, I'm not saying you're wrong because I know that the R-12 substitutes  \\nexist, but this sounds a lot like the 200mpg carbs that the oil companies  \\nkeep us all from getting.\\n\\nMark\\n\\n\"\n",
    "k = preprocessing(a)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW_B7GpQ9_2B"
   },
   "source": [
    "# PUNTO 2\n",
    "\n",
    "- Con los datos normalizados y vectorizados aplique el método LSI. Compare los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAMyKIMv-Jjg"
   },
   "source": [
    "# PUNTO 3\n",
    "\n",
    "- Con los datos normalizados y vectorizados. ¿Es posible aplicar k-means?\n",
    "\n",
    "- En caso de una respuesta afirmativa. Utilice alguno el método del codo, el método de la silueta, y el método GAP para determinar cuáles valores de $k$ (número de clusters) son sugeridos y aplique el modelo.\n",
    "\n",
    "- Comparar resultados con los métodos anteriores: k-means, LDA y LSI.\n",
    "\n",
    "- Concluya"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
